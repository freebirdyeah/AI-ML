{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2olKBLRhCbaB"
   },
   "source": [
    "# Training on MNIST dataset for Handwritten Number Recogniton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWjtH1_lCjhV"
   },
   "source": [
    "### Importing Libraries and important stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jPW-7hKwCWyr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5Wl5DUJCqKo"
   },
   "source": [
    "### Loading Data and preprocessing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mR_DOprNCun3"
   },
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype('float64') / 255\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype('float64') / 255\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSrKIoeVDTnS"
   },
   "source": [
    "### Building our Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fvBD_OJDYeT",
    "outputId": "5dc61a39-0b8b-403e-d2bb-766f02fb0033"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Building the model architechture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIKE_FPeDi0h"
   },
   "source": [
    "### Training our CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "KF5AVEu5Dndm",
    "outputId": "a228271c-3728-4a5e-95ab-81476068b188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9118 - loss: 0.2909 - val_accuracy: 0.9847 - val_loss: 0.0560\n",
      "Epoch 2/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9848 - loss: 0.0460 - val_accuracy: 0.9856 - val_loss: 0.0520\n",
      "Epoch 3/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9909 - loss: 0.0287 - val_accuracy: 0.9862 - val_loss: 0.0459\n",
      "Epoch 4/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9943 - loss: 0.0165 - val_accuracy: 0.9852 - val_loss: 0.0515\n",
      "Epoch 5/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9954 - loss: 0.0142 - val_accuracy: 0.9898 - val_loss: 0.0376\n",
      "Epoch 6/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0108 - val_accuracy: 0.9887 - val_loss: 0.0471\n",
      "Epoch 7/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9979 - loss: 0.0063 - val_accuracy: 0.9892 - val_loss: 0.0482\n",
      "Epoch 8/8\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0050 - val_accuracy: 0.9885 - val_loss: 0.0545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d9d3d3bbf0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=8, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2f2HbbnVDx-5"
   },
   "source": [
    "### Evaluating the Accuracy of our CNN on a given test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NlmhxUbkD6SL",
    "outputId": "c48c1fd5-4514-478a-d130-94e267d9c408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - 2ms/step - accuracy: 0.9909 - loss: 0.0417\n",
      "Test accuracy: 0.9908999800682068\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1x1umbc1D9Nc"
   },
   "source": [
    "### Saving the model to a .h5 file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-U8dxHU4EFz8",
    "outputId": "e8dc433c-47b5-45ae-8dc5-4134c908a434"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"mnist_cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SHOfSV3Fy86"
   },
   "source": [
    "Now we use the tkinter program to draw a number and we input that number to our trained and saved NN (remember the .h5 file?)\n",
    "\n",
    "\n",
    "Go use that program to draw a number and upload it here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzbNLp-WHO8h"
   },
   "source": [
    "### Inverting the handwritten number image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bxrl3maTG75A"
   },
   "source": [
    "The following code snippet will invert the black and white image making it similar to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "E4jqNlDaGoOo"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "\n",
    "image = Image.open('drawn_image.png')\n",
    "inverted_image = PIL.ImageOps.invert(image)\n",
    "inverted_image.save('drawn_inv_image.png')\n",
    "\n",
    "image = Image.open('drawn_inv_image.png')\n",
    "inverted_image = PIL.ImageOps.invert(image)\n",
    "plt.imshow(inverted_image, cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11Fda-jQH-_K"
   },
   "source": [
    "### Use the drawing program and upload it\n",
    "\n",
    "Here's the code for it, run it in your local environment\n",
    "\n",
    "```\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Create a Tkinter window\n",
    "class DrawingApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Drawing Canvas\")\n",
    "        \n",
    "        # Canvas for drawing\n",
    "        self.canvas = tk.Canvas(root, width=280, height=280, bg='white')\n",
    "        self.canvas.pack()\n",
    "        \n",
    "        # Initialize drawing state\n",
    "        self.drawing = False\n",
    "        self.last_x, self.last_y = None, None\n",
    "        \n",
    "        # Event bindings\n",
    "        self.canvas.bind(\"<ButtonPress-1>\", self.start_drawing)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw)\n",
    "        self.canvas.bind(\"<ButtonRelease-1>\", self.stop_drawing)\n",
    "        \n",
    "        # Button to save the drawing\n",
    "        save_button = tk.Button(root, text=\"Save\", command=self.save_image)\n",
    "        save_button.pack()\n",
    "        \n",
    "        # Image to save drawing\n",
    "        self.image = Image.new(\"L\", (280, 280), \"white\")\n",
    "        self.draw_instance = ImageDraw.Draw(self.image)\n",
    "    \n",
    "    def start_drawing(self, event):\n",
    "        self.drawing = True\n",
    "        self.last_x, self.last_y = event.x, event.y\n",
    "    \n",
    "    def draw(self, event):\n",
    "        if self.drawing:\n",
    "            # Draw on canvas\n",
    "            self.canvas.create_line(self.last_x, self.last_y, event.x, event.y, fill=\"black\", width=10)\n",
    "            \n",
    "            # Draw on PIL image\n",
    "            self.draw_instance.line([self.last_x, self.last_y, event.x, event.y], fill=\"black\", width=10)\n",
    "            \n",
    "            self.last_x, self.last_y = event.x, event.y\n",
    "    \n",
    "    def stop_drawing(self, event):\n",
    "        self.drawing = False\n",
    "    \n",
    "    def save_image(self):\n",
    "        self.image = self.image.resize((28, 28))  # Resize to MNIST dimensions\n",
    "        self.image.save(\"drawn_image.png\")\n",
    "        print(\"Image saved as drawn_image.png\")\n",
    "\n",
    "\n",
    "# Run the application\n",
    "root = tk.Tk()\n",
    "app = DrawingApp(root)\n",
    "root.mainloop()\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rc9JM6wlIBT8",
    "outputId": "ec4a451a-e1f3-4fe0-8b73-deed8dced435"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Predicted digit: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7744</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">495,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7744\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m495,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">515,148</span> (1.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m515,148\u001b[0m (1.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">515,146</span> (1.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m515,146\u001b[0m (1.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image  # Import the Image class from Pillow\n",
    "import numpy as np\n",
    "\n",
    "# Load the drawn image\n",
    "img = Image.open(\"drawn_inv_image.png\")\n",
    "\n",
    "# Preprocess the image\n",
    "img_array = np.array(img)  # Normalize pixel values to [0, 1]\n",
    "img_array = img_array.reshape(1, 28, 28, 1)  # Add batch and channel dimensions\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"mnist_cnn_model.h5\")\n",
    "\n",
    "# Predict the digit\n",
    "prediction = model.predict(tf.convert_to_tensor(img_array, dtype=tf.float64))\n",
    "print(prediction)\n",
    "predicted_digit = np.argmax(prediction)  # Get the digit with the highest probability\n",
    "print(\"Predicted digit:\", predicted_digit)\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
