{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure TensorFlow version compatibility\n",
    "print(f\"Using TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EMNIST dataset from TensorFlow Datasets\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset_name = \"emnist/byclass\"\n",
    "(ds_full_train, ds_test), ds_info = tfds.load(\n",
    "    dataset_name,\n",
    "    split=[\"train\", \"test\"],\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "# Train-validation split (90%-10%)\n",
    "train_size = int(0.9 * ds_info.splits['train'].num_examples)\n",
    "val_size = ds_info.splits['train'].num_examples - train_size\n",
    "\n",
    "ds_train = ds_full_train.take(train_size)\n",
    "ds_val = ds_full_train.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (28, 28))  # Resize to 28x28 if needed\n",
    "    image = tf.image.per_image_standardization(image)  # Normalize pixel values\n",
    "    return image, label\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "ds_train = ds_train.map(preprocess).batch(batch_size).shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.map(preprocess).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(preprocess).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Docs\n",
    "\n",
    "Convolutions -> https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "\n",
    "Max Pooling -> https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D\n",
    "\n",
    "ReLU -> https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU\n",
    "\n",
    "Fully Connected Layer -> https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "\n",
    "Flatten has been done for you, do it before you start putting FC layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class SimpleCNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")\n",
    "        self.pool1 = layers.MaxPooling2D((2, 2))\n",
    "        self.conv2 = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")\n",
    "        self.pool2 = layers.MaxPooling2D((2, 2))\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(128, activation=\"relu\")\n",
    "        self.fc2 = layers.Dense(62, activation=\"softmax\")\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(ds_test)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"emnist_cnn_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
